{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "32vyk3_tc2Uf",
    "outputId": "4309a9d3-770d-4bad-a216-bee1c5e26918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '1000', '20', '5', '50', '500', 'None']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "print(os.listdir('F:\\\\Study\\\\money_detection_data\\\\train\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AD14spUMeEoG",
    "outputId": "6c8cf889-1748-4a54-faff-e03f31a4d5c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#dependencies  \n",
    "import keras \n",
    "from keras import Model, Sequential, layers, models\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5IpySBieauS"
   },
   "outputs": [],
   "source": [
    "#variable declerations \n",
    "image_width = 1080\n",
    "image_height = 1080\n",
    "batch_size = 8\n",
    "no_of_training_sample = 250\n",
    "no_of_validation_sample = 70\n",
    "epochs = 70\n",
    "train_path = '/content/gdrive/My Drive/MONEY DETECTION DATA/train'\n",
    "valid_path = '/content/gdrive/My Drive/MONEY DETECTION DATA/valid'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NUeiht7Me5Uu",
    "outputId": "9c4551cf-8dae-4ead-dcbd-4baafc2751ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1080, 1080, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 1080, 1080, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 1080, 1080, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 540, 540, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 540, 540, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 540, 540, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 270, 270, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 270, 270, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 270, 270, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 270, 270, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 270, 270, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 135, 135, 256)     0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 135, 135, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 135, 135, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 135, 135, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 135, 135, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 67, 67, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 67, 67, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 67, 67, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 67, 67, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 67, 67, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 33, 33, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 557568)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 4460552   \n",
      "=================================================================\n",
      "Total params: 24,484,936\n",
      "Trainable params: 4,460,552\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#preparing model \n",
    "model = keras.applications.VGG19(include_top=False, weights='imagenet',input_shape=(image_height,image_width,3))\n",
    "#freezing all the layers except  last layer \n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "#adding custom layers\n",
    "x = model.output\n",
    "x = layers.Flatten()(x)\n",
    "predictions = layers.Dense(8, activation='softmax')(x)\n",
    "model_final = Model(inputs=model.input, outputs=predictions)\n",
    "model_final.compile(loss = 'categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "v5eev6bjioaV",
    "outputId": "da290ee9-274f-4762-c0cb-77fcf4384bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 8 classes.\n",
      "Found 560 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#data augumentation in train set\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rescale = 1./255,\n",
    "    # fill_mode ='nearest',\n",
    "    # zoom_range = 0.3,\n",
    "    # width_shift_range=0.3,\n",
    "    # height_shift_range=0.3,\n",
    "    # rotation_range=30\n",
    ")\n",
    "#data augumentation in valid test\n",
    "valid_data_generator = ImageDataGenerator(\n",
    "    horizontal_flip =True,\n",
    "    rescale = 1./255,\n",
    "    # fill_mode='nearest',\n",
    "    # zoom_range = 0.3,\n",
    "    # width_shift_range = 0.3,\n",
    "    # rotation_range = 30,\n",
    "    # height_shift_range = 0.3\n",
    ")\n",
    "\n",
    "#specifying train data directory and resize\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (image_height, image_width),\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "#specifying test data directory and resize \n",
    "valid_generator = valid_data_generator.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size = (image_height, image_width),\n",
    "    class_mode = 'categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "dg0N6_cMtOJO",
    "outputId": "fc6876c9-5d02-4d7c-fd6f-55490c3ed2a3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b569625115e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_final.fit_generator(train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                           \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_of_training_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_final' is not defined"
     ]
    }
   ],
   "source": [
    "#fit the model \n",
    "model_final.fit_generator(train_generator,\n",
    "                          samples_per_epoch=no_of_training_sample, \n",
    "                          epochs= epochs, \n",
    "                          validation_data=valid_generator,\n",
    "                          \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "Copy of Currency Detection using Transfer Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
